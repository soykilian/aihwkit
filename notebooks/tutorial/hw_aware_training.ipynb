{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "8dRBAFI2xcEK",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# various utility functions\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def _weights_init(m):\n",
    "    if isinstance(m, torch.nn.Linear) or isinstance(m, torch.nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "\n",
    "class LambdaLayer(torch.nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(torch.nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, option=\"A\"):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = torch.nn.BatchNorm2d(planes)\n",
    "        self.conv2 = torch.nn.Conv2d(\n",
    "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = torch.nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = torch.nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == \"A\":\n",
    "                \"\"\"\n",
    "                For CIFAR10 ResNet paper uses option A.\n",
    "                \"\"\"\n",
    "                self.shortcut = LambdaLayer(\n",
    "                    lambda x: F.pad(\n",
    "                        x[:, :, ::2, ::2],\n",
    "                        (0, 0, 0, 0, planes // 4, planes // 4),\n",
    "                        \"constant\",\n",
    "                        0,\n",
    "                    )\n",
    "                )\n",
    "            elif option == \"B\":\n",
    "                self.shortcut = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(\n",
    "                        in_planes,\n",
    "                        self.expansion * planes,\n",
    "                        kernel_size=1,\n",
    "                        stride=stride,\n",
    "                        bias=False,\n",
    "                    ),\n",
    "                    torch.nn.BatchNorm2d(self.expansion * planes),\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self, block, num_blocks, n_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            3, 16, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = torch.nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.linear = torch.nn.Linear(64, n_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def resnet32(n_classes=10):\n",
    "    return ResNet(BasicBlock, [5, 5, 5], n_classes=n_classes)\n",
    "\n",
    "\n",
    "class TorchCutout(object):\n",
    "    def __init__(self, length, fill=(0.0, 0.0, 0.0)):\n",
    "        self.length = length\n",
    "        self.fill = torch.tensor(fill).reshape(shape=(3, 1, 1))\n",
    "\n",
    "    def __call__(self, img):\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "        y = np.random.randint(h)\n",
    "        x = np.random.randint(w)\n",
    "        y1 = np.clip(y - self.length // 2, 0, h)\n",
    "        y2 = np.clip(y + self.length // 2, 0, h)\n",
    "        x1 = np.clip(x - self.length // 2, 0, w)\n",
    "        x2 = np.clip(x + self.length // 2, 0, w)\n",
    "        img[:, y1:y2, x1:x2] = self.fill\n",
    "        return img\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "def load_cifar10(batch_size, path):\n",
    "    transform_train = torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.RandomCrop(32, padding=4),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(\n",
    "                (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "            ),\n",
    "            TorchCutout(length=8),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    transform_test = torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(\n",
    "                (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=path, train=True, download=True, transform=transform_train\n",
    "    )\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=path, train=False, download=True, transform=transform_test\n",
    "    )\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=batch_size, shuffle=True, num_workers=1\n",
    "    )\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=batch_size, shuffle=False, num_workers=1\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9m1qDEsd-C4H"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# - Generic imports\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# - AIHWKIT related imports\n",
    "from aihwkit.nn.conversion import convert_to_analog\n",
    "from aihwkit.optim import AnalogSGD\n",
    "from aihwkit.simulator.presets.utils import IOParameters\n",
    "\n",
    "from aihwkit.simulator.parameters.io import IOParametersIRDropT\n",
    "from aihwkit.inference.noise.pcm import PCMLikeNoiseModel\n",
    "from aihwkit.inference import ReRamCMONoiseModel\n",
    "from aihwkit.inference.compensation.drift import GlobalDriftCompensation\n",
    "from aihwkit.simulator.configs import InferenceRPUConfig\n",
    "from aihwkit.simulator.configs.utils import (\n",
    "    WeightModifierType,\n",
    "    BoundManagementType,\n",
    "    WeightClipType,\n",
    "    NoiseManagementType,\n",
    "    WeightRemapType,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prec = 6\n",
    "output_prec = 8\n",
    "wire = 0.35\n",
    "PCM = False\n",
    "\n",
    "def gen_rpu_config(noise_model, pcm= False):\n",
    "    input_prec = 6\n",
    "    output_prec = 8\n",
    "    my_rpu_config = InferenceRPUConfig()\n",
    "    \n",
    "    my_rpu_config.mapping.digital_bias = True # do the bias of the MVM digitally\n",
    "    my_rpu_config.mapping.max_input_size = 256\n",
    "    my_rpu_config.mapping.max_output_size = 256\n",
    "    my_rpu_config.forward = IOParametersIRDropT()\n",
    "    if pcm:\n",
    "        my_rpu_config.noise_model = PCMLikeNoiseModel(g_max=25.0)\n",
    "        my_rpu_config.drift_compensation = GlobalDriftCompensation()\n",
    "        my_rpu_config.forward.ir_drop_g_ratio = 1.0 / 0.35 / 25e-6 # change to 25w-6 when using PCM\n",
    "    else:\n",
    "        my_rpu_config.noise_model = noise_model \n",
    "        my_rpu_config.drift_compensation = None # by default is GlobalCompensation from PCM\n",
    "        my_rpu_config.forward.ir_drop_g_ratio = 1.0 / 0.35 / (noise_model.g_max*1e-6) # change to 25w-6 when using PCM\n",
    "\n",
    "    #my_rpu_config.drift_compensation = None\n",
    "    my_rpu_config.modifier.std_dev = 0.06\n",
    "    my_rpu_config.modifier.type = WeightModifierType.ADD_NORMAL\n",
    "    my_rpu_config.mapping.weight_scaling_omega = 1.0\n",
    "    my_rpu_config.mapping.weight_scaling_columnwise = False\n",
    "    my_rpu_config.mapping.out_scaling_columnwise = False\n",
    "    my_rpu_config.remap.type = WeightRemapType.LAYERWISE_SYMMETRIC \n",
    "    my_rpu_config.forward.inp_res = 1 / (2**input_prec - 2)\n",
    "    my_rpu_config.forward.out_res = 1 / (2**output_prec - 2)\n",
    "    my_rpu_config.forward.is_perfect = False\n",
    "    #my_rpu_config.forward.out_noise = 0.0 # Output on the current addition (?)\n",
    "    my_rpu_config.forward.ir_drop = 1.0 # TODO set to 1.0 when activating IR drop effects\n",
    "    my_rpu_config.forward.ir_drop_rs = 0.35 # Default: 0.15\n",
    "    my_rpu_config.pre_post.input_range.enable = False\n",
    "    \n",
    "    #my_rpu_config.pre_post.input_range.manage_output_clipping = True\n",
    "    #UNCOMMENT FOR MY MODEL\n",
    "    my_rpu_config.pre_post.input_range.decay = 0.001\n",
    "    my_rpu_config.pre_post.input_range.input_min_percentage = 0.95\n",
    "    my_rpu_config.pre_post.input_range.output_min_percentage = 0.95\n",
    "    my_rpu_config.forward.noise_management = NoiseManagementType.ABS_MAX # Rescale back the output with the scaling for normalizing the input\n",
    "    #my_rpu_config.forward.bound_management = BoundManagementType.ITERATIVE\n",
    "    my_rpu_config.forward.out_bound = 20.0  # quite restric\n",
    "    return my_rpu_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6_She6Vv-C4P"
   },
   "outputs": [],
   "source": [
    "# - Standard train and test routines\n",
    "def train_step(model, optimizer, criterion, trainloader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, targets in trainloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    return train_loss / total, 100.0 * correct / total\n",
    "\n",
    "\n",
    "def test_step(model, criterion, testloader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in testloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    print(f\"Test loss {test_loss/total:.4f} test acc. {100.*correct/total:.2f}%\")\n",
    "    return 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0-82vyr-C4Q",
    "outputId": "05431c47-efa4-4ea6-e759-5e3b5b93f66b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# - Set seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "import os\n",
    "# - Get the dataloader\n",
    "batch_size = 128\n",
    "trainloader, testloader = load_cifar10(\n",
    "    batch_size=batch_size, path=os.path.expanduser(\"~/Data/\")\n",
    ")\n",
    "\n",
    "# - Change to True if one of the models should be re-trained\n",
    "retrain_baseline = False\n",
    "retrain_finetuned_model = False\n",
    "\n",
    "# - Some hyperparameters\n",
    "lr = 0.05\n",
    "epochs = 200\n",
    "epochs_finetuning = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aG-rrTt5-C4R"
   },
   "outputs": [],
   "source": [
    "# - Define model, criterion, optimizer and scheduler.\n",
    "model = resnet32()\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LD4Y2wot-C4R"
   },
   "source": [
    "We typically first pre-train a baseline model that we later fine-tune using noise injection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L_Cvn56G-C4R",
    "outputId": "bd54f7a1-a836-4b27-b627-eb18b524dd14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3073343/3910390277.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"Models/pre_trained_resnet.th\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 0.0016 test acc. 94.12%\n",
      "Pretrained test acc. 94.12%\n"
     ]
    }
   ],
   "source": [
    "# - Pre-training of the network\n",
    "import os\n",
    "if not os.path.exists(\"Models\"):\n",
    "    os.makedirs(\"Models\")\n",
    "if retrain_baseline:\n",
    "    pbar = tqdm(range(epochs))\n",
    "    for epoch in pbar:\n",
    "        train_loss, train_acc = train_step(model, optimizer, criterion, trainloader)\n",
    "        pbar.set_description(f\"Epoch {epoch} Train loss: {train_loss:.4f} train acc. {train_acc:.2f}%\")\n",
    "        if epoch % 5 == 0:\n",
    "            test_step(model, criterion, testloader)\n",
    "        scheduler.step()\n",
    "    torch.save(model.state_dict(), \"Models/pre_trained_model.th\")\n",
    "else:\n",
    "    import requests\n",
    "    url = 'https://aihwkit-tutorial.s3.us-east.cloud-object-storage.appdomain.cloud/pre_trained_model.th'\n",
    "    response = requests.get(url)\n",
    "    with open('Models/pre_trained_resnet.th', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    model.load_state_dict(torch.load(\"Models/pre_trained_resnet.th\", map_location=device))\n",
    "    print(f\"Pretrained test acc. {test_step(model, criterion, testloader)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"/u/mvc/aihwkit/notebooks/tutorial/Models/pre_trained_resnet.th\", map_location=device))\n",
    "print(f\"Pretrained test acc. {test_step(model, criterion, testloader)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analog_hwa = torch.load(\"/u/mvc/aihwkit/notebooks/tutorial/Models/hwa_reram_resnet_6_8bits_input_range.th\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hwa_model = torch.load(\"Models/hwa_reram_resnet_6_8bits_input_range.th\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 0.0026 test acc. 90.22%\n",
      "Programming:  90.22\n",
      "Drifted at t:  1\n",
      "Test loss 0.0026 test acc. 90.41%\n",
      "Drifted at t:  1\n",
      "Test loss 0.0028 test acc. 89.85%\n",
      "Drifted at t:  1\n",
      "Test loss 0.0029 test acc. 89.62%\n",
      "Drifted at t:  1\n",
      "Test loss 0.0027 test acc. 90.06%\n",
      "Drifted at t:  1\n",
      "Test loss 0.0026 test acc. 90.72%\n",
      "Drifted at t:  600\n",
      "Test loss 0.0321 test acc. 13.18%\n",
      "Drifted at t:  600\n",
      "Test loss 0.0350 test acc. 12.47%\n",
      "Drifted at t:  600\n",
      "Test loss 0.0354 test acc. 12.20%\n",
      "Drifted at t:  600\n",
      "Test loss 0.0328 test acc. 13.10%\n",
      "Drifted at t:  600\n",
      "Test loss 0.0343 test acc. 12.68%\n",
      "Drifted at t:  3600\n",
      "Test loss 0.0312 test acc. 11.22%\n",
      "Drifted at t:  3600\n",
      "Test loss 0.0315 test acc. 10.37%\n",
      "Drifted at t:  3600\n",
      "Test loss 0.0343 test acc. 10.30%\n",
      "Drifted at t:  3600\n",
      "Test loss 0.0316 test acc. 10.63%\n",
      "Drifted at t:  3600\n",
      "Test loss 0.0332 test acc. 10.70%\n",
      "Drifted at t:  86400\n",
      "Test loss 0.0275 test acc. 10.31%\n",
      "Drifted at t:  86400\n",
      "Test loss 0.0269 test acc. 10.23%\n",
      "Drifted at t:  86400\n",
      "Test loss 0.0267 test acc. 10.45%\n",
      "Drifted at t:  86400\n",
      "Test loss 0.0271 test acc. 10.27%\n",
      "Drifted at t:  86400\n",
      "Test loss 0.0285 test acc. 10.15%\n",
      "Drifted at t:  604800\n",
      "Test loss 0.0256 test acc. 10.05%\n",
      "Drifted at t:  604800\n",
      "Test loss 0.0265 test acc. 10.00%\n",
      "Drifted at t:  604800\n",
      "Test loss 0.0260 test acc. 10.08%\n",
      "Drifted at t:  604800\n",
      "Test loss 0.0265 test acc. 10.26%\n",
      "Drifted at t:  604800\n",
      "Test loss 0.0270 test acc. 9.97%\n",
      "Drifted at t:  2592000\n",
      "Test loss 0.0259 test acc. 9.65%\n",
      "Drifted at t:  2592000\n",
      "Test loss 0.0260 test acc. 9.99%\n",
      "Drifted at t:  2592000\n",
      "Test loss 0.0263 test acc. 9.71%\n",
      "Drifted at t:  2592000\n",
      "Test loss 0.0258 test acc. 9.98%\n",
      "Drifted at t:  2592000\n",
      "Test loss 0.0254 test acc. 10.53%\n",
      "Drifted at t:  31536000\n",
      "Test loss 0.0262 test acc. 10.01%\n",
      "Drifted at t:  31536000\n",
      "Test loss 0.0260 test acc. 10.15%\n",
      "Drifted at t:  31536000\n",
      "Test loss 0.0254 test acc. 9.89%\n",
      "Drifted at t:  31536000\n",
      "Test loss 0.0261 test acc. 10.35%\n",
      "Drifted at t:  31536000\n",
      "Test loss 0.0257 test acc. 9.54%\n",
      "Drifted at t:  63072000\n",
      "Test loss 0.0263 test acc. 9.96%\n",
      "Drifted at t:  63072000\n",
      "Test loss 0.0256 test acc. 10.43%\n",
      "Drifted at t:  63072000\n",
      "Test loss 0.0257 test acc. 10.28%\n",
      "Drifted at t:  63072000\n",
      "Test loss 0.0268 test acc. 10.62%\n",
      "Drifted at t:  63072000\n",
      "Test loss 0.0261 test acc. 10.20%\n",
      "Drifted at t:  157680000\n",
      "Test loss 0.0261 test acc. 9.94%\n",
      "Drifted at t:  157680000\n",
      "Test loss 0.0260 test acc. 9.33%\n",
      "Drifted at t:  157680000\n",
      "Test loss 0.0255 test acc. 10.14%\n",
      "Drifted at t:  157680000\n",
      "Test loss 0.0261 test acc. 10.09%\n",
      "Drifted at t:  157680000\n",
      "Test loss 0.0259 test acc. 9.41%\n",
      "Drifted at t:  315360000\n",
      "Test loss 0.0260 test acc. 10.28%\n",
      "Drifted at t:  315360000\n",
      "Test loss 0.0255 test acc. 9.89%\n",
      "Drifted at t:  315360000\n",
      "Test loss 0.0256 test acc. 10.36%\n",
      "Drifted at t:  315360000\n",
      "Test loss 0.0255 test acc. 10.17%\n",
      "Drifted at t:  315360000\n",
      "Test loss 0.0252 test acc. 9.90%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    w, _ = (\\n        converted_model\\n        .layer3[0]\\n        .conv1.analog_module.get_weights(apply_weight_scaling=True)\\n        )\\n        real_weights = model.layer3[0].conv1.weight\\n        real_weights = real_weights.flatten(start_dim=1, end_dim=-1)\\n        print(real_weights.shape)\\n        print(w.shape)\\n        print(\"Weight error:\", torch.mean(torch.abs(real_weights.cpu() - w.cpu())).item())\\n    plt.hist(w.flatten().detach().numpy(), color=color[i], bins=300, alpha =0.5, label=f\"Time of inference = {labels[i]}\")\\n    mean_w = w.flatten().detach().numpy()\\n    std_w = mean_w.std()\\n    mean_w = mean_w.mean()\\n    #plt.axvline(mean_w - std_w, color=\\'b\\', linestyle=\\'dotted\\', linewidth=2, label =f\"STD:{std_w:.4f}\")\\n    #plt.axvline(mean_w + std_w, color=\\'b\\', linestyle=\\'dotted\\', linewidth=2)\\n    #plt.axvspan(mean_w - std_w, mean_w + std_w, color=\\'blue\\', alpha=0.2)\\n    #plt.axvline(mean_w)\\n    drifted_test_accs[i]/= n_rep\\nplt.legend()\\nplt.xlabel(\"Unnormalized weight\")\\nplt.ylabel(\"Count\")\\n#plt.title(f\"Time of inference = {labels[i]}\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\"mean\": [-0.08900206],\n",
    "from aihwkit.inference.noise.config import SimulationContextWrapper\n",
    "import matplotlib.pyplot as plt\n",
    "g_max = 90\n",
    "g_min = 10\n",
    "acceptance_range=0.2\n",
    "single_device=True\n",
    "prog_overshoot=0.0\n",
    "reram_noise =ReRamCMONoiseModel(g_max=g_max, g_min=g_min,\n",
    "                                                        acceptance_range=acceptance_range,\n",
    "                                                        resistor_compensator=prog_overshoot,\n",
    "                                                        single_device=single_device)\n",
    "rpu_config = gen_rpu_config(noise_model=reram_noise)\n",
    "#rpu_config = gen_rpu_config()\n",
    "converted_model = convert_to_analog(model, rpu_config)\n",
    "#converted_model.load_state_dict(analog_hwa)\n",
    "#converted_model = analog_hwa\n",
    "\n",
    "#t_inferences = [0, 1, 3600, 3600 * 24, 3600 * 24 * 365 * 10]\n",
    "#t_inferences = [10, 10e3, 10e4, 10e5]\n",
    "t_inferences = [1, 60*10, 3600, 3600 * 24, 3600 * 24*7, 3600 * 24 *30, 3600 * 24 *365, 3600 * 24 *365*2, 3600 * 24 *365*5, 3600 * 24 * 365 * 10]    \n",
    "#t_inferences = [0, 3600 * 24 * 365 * 10]\n",
    "#labels = [\"0s\", \"1s\", \"1h\", \"1d\", \"10y\"]\n",
    "print(\"Programming: \",test_step(converted_model, criterion, testloader))\n",
    "converted_model.eval()\n",
    "converted_model.program_analog_weights()\n",
    "labels = [\"0s\",  \"10y\"]\n",
    "color = [ 'lightskyblue', 'lightcoral']\n",
    "n_rep = 5\n",
    "drifted_test_accs = torch.zeros(size=(len(t_inferences), n_rep))\n",
    "plt.figure()\n",
    "for i,t in enumerate(t_inferences):\n",
    "    for j in range(n_rep):\n",
    "        #SimulationContextWrapper.t_inference = t\n",
    "        converted_model.drift_analog_weights(t)\n",
    "        print(\"Drifted at t: \", t)\n",
    "        accuracy = test_step(converted_model, criterion, testloader)\n",
    "        drifted_test_accs[i,j] = accuracy \n",
    "        #print(f\"Accuracy of the analog model: {accuracy:.2f}%\")\n",
    "        \n",
    "\"\"\"\n",
    "    w, _ = (\n",
    "        converted_model\n",
    "        .layer3[0]\n",
    "        .conv1.analog_module.get_weights(apply_weight_scaling=True)\n",
    "        )\n",
    "        real_weights = model.layer3[0].conv1.weight\n",
    "        real_weights = real_weights.flatten(start_dim=1, end_dim=-1)\n",
    "        print(real_weights.shape)\n",
    "        print(w.shape)\n",
    "        print(\"Weight error:\", torch.mean(torch.abs(real_weights.cpu() - w.cpu())).item())\n",
    "    plt.hist(w.flatten().detach().numpy(), color=color[i], bins=300, alpha =0.5, label=f\"Time of inference = {labels[i]}\")\n",
    "    mean_w = w.flatten().detach().numpy()\n",
    "    std_w = mean_w.std()\n",
    "    mean_w = mean_w.mean()\n",
    "    #plt.axvline(mean_w - std_w, color='b', linestyle='dotted', linewidth=2, label =f\"STD:{std_w:.4f}\")\n",
    "    #plt.axvline(mean_w + std_w, color='b', linestyle='dotted', linewidth=2)\n",
    "    #plt.axvspan(mean_w - std_w, mean_w + std_w, color='blue', alpha=0.2)\n",
    "    #plt.axvline(mean_w)\n",
    "    drifted_test_accs[i]/= n_rep\n",
    "plt.legend()\n",
    "plt.xlabel(\"Unnormalized weight\")\n",
    "plt.ylabel(\"Count\")\n",
    "#plt.title(f\"Time of inference = {labels[i]}\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(drifted_test_accs, \"resnet_baseline_1m_10y.th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rpu_config(noise_model, pcm= False):\n",
    "    input_prec = 6\n",
    "    output_prec = 8\n",
    "    my_rpu_config = InferenceRPUConfig()\n",
    "    my_rpu_config.mapping.digital_bias = True # do the bias of the MVM digitally\n",
    "    my_rpu_config.mapping.max_input_size = 256\n",
    "    my_rpu_config.mapping.max_output_size = 256\n",
    "    my_rpu_config.forward = IOParametersIRDropT()\n",
    "    if pcm:\n",
    "        my_rpu_config.noise_model = PCMLikeNoiseModel(g_max=25.0)\n",
    "        my_rpu_config.drift_compensation = GlobalDriftCompensation()\n",
    "        my_rpu_config.forward.ir_drop_g_ratio = 1.0 / 0.35 / 25e-6 # change to 25w-6 when using PCM\n",
    "    else:\n",
    "        my_rpu_config.noise_model = noise_model \n",
    "        my_rpu_config.drift_compensation = None # by default is GlobalCompensation from PCM\n",
    "        my_rpu_config.forward.ir_drop_g_ratio = 1.0 / 0.35 / (noise_model.g_max*1e-6) # change to 25w-6 when using PCM\n",
    "\n",
    "    #my_rpu_config.drift_compensation = None\n",
    "    my_rpu_config.modifier.std_dev = 0.06\n",
    "    my_rpu_config.modifier.type = WeightModifierType.ADD_NORMAL\n",
    "    \n",
    "    my_rpu_config.forward.inp_res = 1 / (2**input_prec - 2)\n",
    "    my_rpu_config.forward.out_res = 1 / (2**output_prec - 2)\n",
    "    my_rpu_config.forward.is_perfect = False\n",
    "    #my_rpu_config.forward.out_noise = 0.0 # Output on the current addition (?)\n",
    "    my_rpu_config.forward.ir_drop = 1.0 # TODO set to 1.0 when activating IR drop effects\n",
    "    my_rpu_config.forward.ir_drop_rs = 0.35 # Default: 0.15\n",
    "    my_rpu_config.pre_post.input_range.enable = True\n",
    "    \n",
    "    #my_rpu_config.pre_post.input_range.manage_output_clipping = True\n",
    "    my_rpu_config.pre_post.input_range.decay = 0.001\n",
    "    my_rpu_config.pre_post.input_range.input_min_percentage = 0.95\n",
    "    my_rpu_config.pre_post.input_range.output_min_percentage = 0.95\n",
    "    my_rpu_config.mapping.weight_scaling_omega = 1.0\n",
    "    my_rpu_config.mapping.weight_scaling_columnwise = True\n",
    "    my_rpu_config.mapping.out_scaling_columnwise = False\n",
    "    #my_rpu_config.forward.noise_management = NoiseManagementType.ABS_MAX # Rescale back the output with the scaling for normalizing the input\n",
    "    my_rpu_config.forward.bound_management = BoundManagementType.ITERATIVE\n",
    "    my_rpu_config.clip.type = WeightClipType.LAYER_GAUSSIAN\n",
    "    my_rpu_config.clip.sigma = 2.5\n",
    "    my_rpu_config.forward.out_bound = 100.0  # quite restric\n",
    "    return my_rpu_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_max = 50\n",
    "g_min = 10\n",
    "acceptance_range=0.2\n",
    "single_device=False\n",
    "prog_overshoot=0.0\n",
    "reram_noise =ReRamCMONoiseModel(g_max=g_max, g_min=g_min,\n",
    "                                                        acceptance_range=acceptance_range,\n",
    "                                                        resistor_compensator=prog_overshoot,\n",
    "                                                        single_device=single_device)\n",
    "rpu_config = gen_rpu_config(noise_model=reram_noise)\n",
    "#rpu_config = gen_rpu_config()\n",
    "analog_model = convert_to_analog(model, rpu_config)\n",
    "dict = torch.load(\"/u/mvc/aihwkit/notebooks/tutorial/Models/hwa_reram_resnet_6_8bits_input_range_Claudia.th\", map_location=\"cuda\")\n",
    "dict['linear.bias'] = torch.Tensor([ 0.0046, -0.0444,  0.0443,  0.0702,  0.0274,  0.0345,  0.0014, -0.0442,\n",
    "        -0.0251, -0.0688])\n",
    "analog_model.load_state_dict(dict\n",
    ")\n",
    "analog_model.eval()\n",
    "analog_model.program_analog_weights(noise_model=reram_noise)\n",
    "t_inferences =  [1, 60*10, 3600, 3600 * 24, 3600 * 24*7, 3600 * 24 *30, 3600 * 24 *365, 3600 * 24 *365*2, 3600 * 24 *365*5, 3600 * 24 * 365 * 10]    \n",
    "n_rep = 2\n",
    "drifted_test_accs = torch.zeros(size=(len(t_inferences),n_rep))\n",
    "for i,t in enumerate(t_inferences):\n",
    "    for j in range(n_rep):\n",
    "        analog_model.drift_analog_weights(t)\n",
    "        print(\"Drifted at t: \", t)\n",
    "        accuracy = test_step(analog_model, criterion, testloader)\n",
    "        drifted_test_accs[i, j] = accuracy\n",
    "        print(f\"Accuracy of the analog model: {accuracy:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(drifted_test_accs, \"/u/mvc/aihwkit/drift_compensation_NNs/hwa_resnet_v2_2T2R_baseline.th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = torch.load(\"/u/mvc/aihwkit/notebooks/tutorial/Models/hwa_reram_June_resnet.th\", map_location=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict['linear.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(\"/u/mvc/aihwkit/notebooks/reram_accuracy_hwa.th\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDdP2piA-C4S"
   },
   "source": [
    "We first convert our model to an analog model using `convert_to_analog` where we pass the model and the RPU config. The optimizer, in this case, `AnalogSGD`.\n",
    "The rest is standard training. Analog models can be easily saved like regular models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original config\n",
    "def gen_rpu_config(noise_model):\n",
    "    rpu_config = InferenceRPUConfig()\n",
    "    rpu_config.modifier.std_dev = 0.06\n",
    "    rpu_config.modifier.type = WeightModifierType.ADD_NORMAL\n",
    "\n",
    "    rpu_config.mapping.digital_bias = True\n",
    "    rpu_config.mapping.weight_scaling_omega = 1.0\n",
    "    rpu_config.mapping.weight_scaling_columnwise = False\n",
    "    rpu_config.mapping.out_scaling_columnwise = False\n",
    "    rpu_config.remap.type = WeightRemapType.LAYERWISE_SYMMETRIC\n",
    "    rpu_config.mapping.max_input_size = 256\n",
    "    rpu_config.mapping.max_output_size = 256\n",
    "    rpu_config.clip.type = WeightClipType.LAYER_GAUSSIAN\n",
    "    rpu_config.clip.sigma = 2.0\n",
    "\n",
    "    rpu_config.forward = IOParameters()\n",
    "    rpu_config.forward.is_perfect = False\n",
    "    rpu_config.forward.out_noise = 0.04\n",
    "    rpu_config.forward.inp_bound = 1.0\n",
    "    rpu_config.forward.inp_res = 1 / (2**8 - 2)\n",
    "    rpu_config.forward.out_bound = 10\n",
    "    rpu_config.forward.out_res = 1 / (2**8 - 2)\n",
    "    rpu_config.forward.bound_management = BoundManagementType.NONE\n",
    "    rpu_config.forward.noise_management = NoiseManagementType.NONE\n",
    "\n",
    "    rpu_config.pre_post.input_range.enable = True\n",
    "    rpu_config.pre_post.input_range.decay = 0.01\n",
    "    rpu_config.pre_post.input_range.init_from_data = 50\n",
    "    rpu_config.pre_post.input_range.init_std_alpha = 3.0\n",
    "    rpu_config.pre_post.input_range.input_min_percentage = 0.995\n",
    "    rpu_config.pre_post.input_range.manage_output_clipping = False\n",
    "\n",
    "    rpu_config.noise_model = noise_model\n",
    "    rpu_config.drift_compensation = None\n",
    "    return rpu_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CF6ddwgw-C4S",
    "outputId": "17dbd555-d243-4cac-eed6-c8652d8e79bb"
   },
   "outputs": [],
   "source": [
    "# - Fine-tuning\n",
    "retrain_finetuned_model = False\n",
    "g_max = 90\n",
    "g_min = 10\n",
    "prog_overshoot =0.0 #1.235\n",
    "single_device = True\n",
    "acceptance_range = 0.2\n",
    "reram_noise =ReRamCMONoiseModel(g_max=g_max, g_min=g_min,\n",
    "                                                        acceptance_range=acceptance_range,\n",
    "                                                        resistor_compensator=prog_overshoot,\n",
    "                                                        single_device=single_device)\n",
    "analog_model = convert_to_analog(model, gen_rpu_config(noise_model=reram_noise))\n",
    "if retrain_finetuned_model:\n",
    "    optimizer = AnalogSGD(\n",
    "        analog_model.parameters(), lr=lr / 10.0, momentum=0.9, weight_decay=5e-4\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    test_accs = torch.empty(epochs_finetuning)\n",
    "    pbar = tqdm(range(epochs_finetuning))\n",
    "    for epoch in pbar:\n",
    "        train_loss, train_acc = train_step(analog_model, optimizer, criterion, trainloader)\n",
    "        pbar.set_description(f\"Epoch {epoch} Train loss: {train_loss:.4f} train acc. {train_acc:.2f}%\")\n",
    "        test_accs[epoch] = test_step(analog_model, criterion, testloader)\n",
    "        scheduler.step()\n",
    "\n",
    "    torch.save(analog_model.state_dict(), \"/u/mvc/aihwkit/notebooks/tutorial/Models/hwa_reram_June_resnet.th\")\n",
    "    #torch.save(test_accs, \"Models/test_accs.th\")\n",
    "\n",
    "else:\n",
    "    import requests\n",
    "    url_test_accs = 'https://aihwkit-tutorial.s3.us-east.cloud-object-storage.appdomain.cloud/test_accs.th'\n",
    "    url_finetuned_model = 'https://aihwkit-tutorial.s3.us-east.cloud-object-storage.appdomain.cloud/finetuned_model_0.9.1.th'\n",
    "    \n",
    "    response_test_accs = requests.get(url_test_accs)\n",
    "    with open('Models/test_accs.th', 'wb') as f:\n",
    "        f.write(response_test_accs.content)\n",
    "    \n",
    "    response_finetuned_model = requests.get(url_finetuned_model)\n",
    "\n",
    "    with open('Models/finetuned_model_0.9.1.th', 'wb') as f:\n",
    "        f.write(response_finetuned_model.content)\n",
    "\n",
    "    test_accs = torch.load(\"Models/test_accs.th\")\n",
    "    analog_model.load_state_dict(\n",
    "        torch.load(\"Models/finetuned_model_0.9.1.th\", map_location=device)\n",
    "    )\n",
    "    print(f\"Finetuned test acc. {test_step(analog_model, criterion, testloader)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "Lxm4YHJz-C4T",
    "outputId": "4037e66a-aeb9-4a3b-e691-9d41cc98f9ad"
   },
   "outputs": [],
   "source": [
    "plt.title(\"Finetunig test accuracy\")\n",
    "plt.plot(test_accs, marker=\"d\", linestyle=\"--\", color=\"b\")\n",
    "plt.ylabel(\"Test acc. (%)\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqTcidHy-C4U"
   },
   "source": [
    "We can also verify that the weights are clipped by looking at one random weight matrix in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "RMHdErKQ-C4U",
    "outputId": "5634dc2f-15bb-407c-f9e9-757497359c71"
   },
   "outputs": [],
   "source": [
    "w, _ = (\n",
    "    analog_model\n",
    "    .layer3[0]\n",
    "    .conv1.analog_module.get_weights(apply_weight_scaling=True)\n",
    ")\n",
    "plt.hist(w.flatten().detach().numpy(), color=\"r\", bins=50)\n",
    "plt.xlabel(\"Unnormalized weight\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrLKLZNb-C4V"
   },
   "source": [
    "Finally, we would like to see how robust our model is. We first have to convert our pre-trained model to analog.\n",
    "We then repeatedly call `drift_analog_weights` with a time value (in seconds). This simulates the drifting of the weights to the specified time. Note that this call also programs the weights, i.e. it simulates programming by applying specific programming noise. This noise model is defined in the `noise_model` of the RPU config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uAF1fy68-C4V",
    "outputId": "c5e5762b-cb7b-4dba-8ff9-a33bdd885468"
   },
   "outputs": [],
   "source": [
    "rpu_conf = gen_rpu_config()\n",
    "converted_model = convert_to_analog(model, rpu_conf)\n",
    "# - For programming the model, we need to put it into eval() mode\n",
    "converted_model = converted_model.eval()\n",
    "#analog_model = analog_model.eval()\n",
    "# - We repeat each measurement 5 times\n",
    "n_rep = 1\n",
    "t_inferences = [60., 3600., 86400., 2592000., 31104000.]\n",
    "drifted_test_accs_baseline = torch.zeros(size=(len(t_inferences),n_rep))\n",
    "converted_model.program_analog_weights(noise_model = rpu_conf.noise_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer1[0].conv1.weight[:,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_model.get_weights()['layer1.0.conv1.analog_module'][0][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rep = 1\n",
    "#t_inferences = [60., 3600., 86400., 2592000., 31104000.]\n",
    "t_inferences = [1., 10., 60.]\n",
    "drifted_test_accs = torch.zeros(size=(len(t_inferences),n_rep))\n",
    "drifted_test_accs_baseline = torch.zeros(size=(len(t_inferences),n_rep))\n",
    "prog = test_step(converted_model, criterion, testloader)\n",
    "print(prog)\n",
    "for i,t in enumerate(t_inferences):\n",
    "    for j in range(n_rep):\n",
    "        analog_model.drift_analog_weights(t)\n",
    "        print(analog_model.get_weights()['layer1.0.conv1.analog_module'][0][:,0])\n",
    "        print(\"Drifted at t: \", t)\n",
    "        drifted_test_accs_baseline[i,j] = test_step(analog_model, criterion, testloader)\n",
    "        print(drifted_test_accs_baseline[i,j])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
